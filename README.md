# üåßÔ∏è Previs√£o de Chuva com Machine Learning: Insights da Competi√ß√£o Kaggle Playground Series S5E4

Hoje quero compartilhar o notebook que desenvolvi para a competi√ß√£o **Kaggle Playground Series S5E4**, cujo objetivo era prever a **probabilidade de chuva** com base em vari√°veis meteorol√≥gicas. Al√©m de apresentar os insights e t√©cnicas utilizadas, quero destacar por que cada passo foi crucial para o desempenho do modelo ‚Äî e tamb√©m refletir sobre o que aprendi durante o processo.

## O Problema
O dataset de treino continha **2.190 amostras** e **13 vari√°veis**, sendo a coluna **rainfall** o target (bin√°rio: 1 para chuva e 0 para n√£o chuva). Os dados estavam bem organizados, sem valores faltantes no conjunto de teste, exceto por um √∫nico valor ausente no conjunto de treino, que foi facilmente imputado. Essa limpeza inicial simplificou o pr√©-processamento e permitiu focar diretamente na an√°lise.

## üîç Explora√ß√£o e Pr√©-Processamento
O notebook come√ßa com visualiza√ß√µes das distribui√ß√µes das vari√°veis. Gr√°ficos de histograma ajudaram a identificar padr√µes, outliers e comportamentos espec√≠ficos. A aus√™ncia de vari√°veis categ√≥ricas facilitou ainda mais o processamento dos dados.

Ao analisar a **matriz de correla√ß√£o**, identifiquei quatro vari√°veis altamente correlacionadas, indicando **multicolinearidade**. Esse fen√¥meno pode prejudicar tanto o desempenho quanto a interpretabilidade do modelo. Para confirmar essa suspeita, calculei o **Fator de Infla√ß√£o de Vari√¢ncia (VIF)**, que refor√ßou a necessidade de lidar com essas correla√ß√µes.

![Correlation Matrix](corr.png)

Para padronizar os dados, apliquei o **StandardScaler**, garantindo que todas as vari√°veis estivessem na mesma escala. Em seguida, utilizei o **PCA (Principal Component Analysis)** para reduzir a dimensionalidade, capturando a maior parte da vari√¢ncia dos dados enquanto otimizava o tempo de treinamento e evitava overfitting. Ap√≥s analisar o gr√°fico de vari√¢ncia acumulada explicada pelo PCA, decidi utilizar **6 componentes**, que representavam cerca de **95% da varia√ß√£o total** dos dados.

![PCA](pca.png)

## ‚öñÔ∏è Desafio do Desbalanceamento
Outro ponto importante foi o desbalanceamento do dataset: cerca de **75% das amostras pertenciam √† classe "chuva" (1)**, enquanto apenas **25% eram da classe "n√£o chuva" (0)**.

![Dist](dist.png)

Para evitar que o modelo fosse enviesado em favor da classe majorit√°ria, apliquei a t√©cnica **SMOTE (Synthetic Minority Over-sampling Technique)** para balancear as classes. Ap√≥s o balanceamento, reapliquei o **PCA com 6 componentes** para manter a consist√™ncia da redu√ß√£o de dimensionalidade.

## ü§ñ Testando Modelos
Testei **8 algoritmos diferentes**, desde modelos cl√°ssicos como **Regress√£o Log√≠stica** e **√Årvores de Decis√£o**, at√© m√©todos avan√ßados como **XGBoost** e **LightGBM**. Utilizei a m√©trica **ROC-AUC** como principal indicador de desempenho e apliquei **valida√ß√£o cruzada estratificada**, garantindo uma avalia√ß√£o robusta e preservando a propor√ß√£o das classes em cada fold.

Entre todos os modelos testados, o **Random Forest Classifier** se destacou como o mais robusto e eficiente, apresentando:
- **ROC-AUC m√©dio**: **0.9437** (o mais alto entre todos os modelos)
- **Desvio padr√£o**: **0.0075** (segunda menor varia√ß√£o entre os folds)

Com base nesses resultados, parti para o ajuste fino de hiperpar√¢metros utilizando **Grid Search**. Os melhores par√¢metros encontrados foram:

```python
{'n_estimators': 200,
'min_samples_split': 2,
'min_samples_leaf': 1,
'max_features': 'sqrt',
'max_depth': None,
'bootstrap': True}
```

Esse ajuste resultou em um leve incremento no **ROC-AUC**, elevando-o para **0.9446**.

## üìä Submiss√£o e Reflex√µes Finais
Ap√≥s todo o processo, treinei o modelo final com os par√¢metros ajustados e submeti as previs√µes. Meu resultado final foi:
- **Private Score** (calculado no fim da competi√ß√£o utilizando completo): **0.83588**
- **Public Score** (calculado a cada submiss√£o utilizando apenas 20% do dataset): **0.85800**

No entanto, ao final da competi√ß√£o, descobri algo surpreendente: o modelo que melhor performou com todos os dados dispon√≠veis foi o **Logistic Regression**, utilizado como **baseline** inicial e sem nenhum ajuste de hiperpar√¢metros. Esse modelo alcan√ßou:
- **Private Score**: **0.88138**
- **Public Score**: **0.84928**

Essa experi√™ncia me ensinou uma li√ß√£o valiosa: nem sempre os modelos mais complexos s√£o os melhores. √Äs vezes, solu√ß√µes simples e robustas podem superar abordagens sofisticadas, especialmente quando os dados est√£o bem estruturados e as rela√ß√µes entre as vari√°veis s√£o lineares ou quase lineares.

#MachineLearning #DataScience #Kaggle #AI #RainfallPrediction #Previs√£oClim√°tica #AnaliseDeDados #AprendizadoDeM√°quina #CienciaDeDados
